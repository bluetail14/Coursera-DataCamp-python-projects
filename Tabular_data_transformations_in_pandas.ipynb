{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdk import datalake\n",
    "from sdk.datalake_publishing import DPCPublishing\n",
    "import pandas as pd\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of new files\n",
    "files_updated = datalake.batch_files_recent('length_extract','length_transform')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # If there are any new files, process them in turn\n",
    "if files_updated:  \n",
    "\n",
    "#    for length_file in files_updated:     \n",
    "#    x=0    \n",
    "    for l_file in datalake.list_batch_files('recorded_length_extract'): \n",
    "\n",
    "\n",
    "    #    print(l_file + str(2))\n",
    "        output_file = length_file.replace('recorded_length','aggregated_length')\n",
    "        \n",
    "         # exclude the file names starting with 'recorded_m'\n",
    "        if l_file.startswith('recorded_m'): \n",
    "            continue\n",
    "\n",
    "        # load the lengths data in inches from the Data Lake, and import the parquet file into a dataframe\n",
    "\n",
    "        length_content_in = datalake.load_from_extract('recorded_length_in_extract', length_in_file)  \n",
    "    #    print(l_file + str(3))\n",
    "        df_in = pd.read_parquet(BytesIO(length_content_in))\n",
    "    #    print(l_file + str(4))\n",
    "\n",
    "            # Total by Item Name and by Year, and reset the index to flatten the column headings\n",
    "        df_in = df_in.groupby(['Item Name','Year','Quantity','Measure_Type']).sum().reset_index()\n",
    "    #    print(l_file + str(5))\n",
    "\n",
    "            # load the length data in cm from the Data Lake, and import the parquet file into a dataframe\n",
    "        length_content_cm = datalake.load_from_extract('recorded_length_cm_extract', length_cm_file)  \n",
    "    #    print(l_file + str(6))\n",
    "        df_cm = pd.read_parquet(BytesIO(length_content_cm))\n",
    "    #    print(l_file + str(7))\n",
    "\n",
    "        # if the rows are not empty\n",
    "        if not df_cm.empty:\n",
    "    #        print(l_file + str(8))\n",
    "            df_cm = df_cm.groupby(['Item Name', 'Year', 'Quantity', 'Measure_Type']).sum().reset_index()\n",
    "    #        print(l_file + str(9))\n",
    "            df_cm['Length_in'] = df_cm['Length'].apply(lambda x: x/2.54 if x>0 else 0)\n",
    "    #        print(l_file + str(10))\n",
    "            df_cm_converted = df_gas[['Item Name','Year','Quantity','Measure_Type','Length_in']].copy()\n",
    "    #        print(l_file + str(11))\n",
    "            df_cm_converted['Unit'] = 'inches'\n",
    "    #        print(l_file + str(12))\n",
    "            df_cm_converted.rename(columns={'Length_in':'Length'}, inplace=True)\n",
    "\n",
    "            # total by Item Name and by Year, and reset the index to flatten the column headings\n",
    "\n",
    "               df_cm_converted = df_cm.groupby(['Item Name','Year','Quantity','Measure_Type']).sum().reset_index()\n",
    "\n",
    "            # Create a combined dataframe with both inches and cm:\n",
    "            df_total = pd.concat([df_in, df_cm_converted], ignore_index=True)\n",
    "          \n",
    "            df_total = df_total.groupby(['Item Name','Year','Quantity','Measure_Type']).sum().reset_index()\n",
    "    \n",
    "\n",
    "        # combine all three datframes\n",
    "            df_final = pd.concat([df_cm, df_in, df_total], ignore_index=True)\n",
    "            df_final.insert(0, \"Metric\", 'Reported Sales')\n",
    "            df_final = df_final.groupby(['Item Name','Metric','Year','Quantity','Fabric_Type']).sum().reset_index()\n",
    "            df_final = df_final[['Item Name','Metric', 'Fabric_Type','Year','Quantity','Length']].sort_values(by=['Item Name', 'Year', 'Fabric_Type'])\n",
    "\n",
    "            df_final= df_final.loc[df_final['Year'] != 0]\n",
    "\n",
    "#           print(df_final)\n",
    "\n",
    "            cnt=df_final['Item Name'].nunique()\n",
    "            x+=cnt       \n",
    "    \n",
    "    #        print(df_in['Company Name'].nunique())\n",
    "    \n",
    "                  #Save new file\n",
    "            datalake.save_transform_parquet('length_aggregated_transform', df_final, output_file)\n",
    "\n",
    "    print ('\\n' f'COUNT: {x}')  # how many items get processed \n",
    "#  \n",
    "#    print(cm_file + str(13))\n",
    "\n",
    "#    print(cm_file + str(14)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
